{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72cb0e86-6c72-4a77-adb7-dff8000161b9",
   "metadata": {},
   "source": [
    "# In this notebook, we apply SMOTE to our filtered databank to later apply to our object feature autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31345b07-fb8f-4c3d-9edd-737829e96d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os, io, gzip, glob, random, csv, json, requests\n",
    "from astropy.io import fits\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lasair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b20404-b063-4fd2-83dc-8bdde9102edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load databank\n",
    "df_str = pd.read_csv(\"training_data.csv\", dtype=str, keep_default_na=False)\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "\n",
    "FILTER_COLS = [\n",
    "    \"dmdt_g_err\",\"dmdt_r_err\",\n",
    "    \"mag_g02\",\"mag_g08\",\"mag_g28\",\n",
    "    \"mag_r02\",\"mag_r08\",\"mag_r28\",\n",
    "]\n",
    "\n",
    "# Coerce to numeric \n",
    "for c in FILTER_COLS:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Kill inf/-inf as well\n",
    "df[FILTER_COLS] = df[FILTER_COLS].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Filter to get rid of non-detections and large errors \n",
    "mask = (\n",
    "    df[\"dmdt_g_err\"].between(-1, 1, inclusive=\"both\") &\n",
    "    df[\"dmdt_r_err\"].between(-1, 1, inclusive=\"both\") &\n",
    "    df[\"mag_g02\"].between(0, 30, inclusive=\"both\") &\n",
    "    df[\"mag_g08\"].between(0, 30, inclusive=\"both\") &\n",
    "    df[\"mag_g28\"].between(0, 30, inclusive=\"both\") &\n",
    "    df[\"mag_r02\"].between(0, 30, inclusive=\"both\") &\n",
    "    df[\"mag_r08\"].between(0, 30, inclusive=\"both\") &\n",
    "    df[\"mag_r28\"].between(0, 30, inclusive=\"both\")\n",
    ")\n",
    "\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "df_str = df_str.loc[mask].reset_index(drop=True)\n",
    "\n",
    "LABEL_COL = \"source_label\"\n",
    "SENTINEL_UNKNOWN = -999\n",
    "UNK_EPS = 1e-6\n",
    "\n",
    "# Normalizing labels\n",
    "def _norm_label(s):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    t = str(s).strip().lower().replace(\" \", \"\")\n",
    "    if t in {\"snia\",\"sn-ia\",\"sn_ia\"}: return \"SN Ia\"\n",
    "    if t in {\"snii\",\"sn-ii\",\"sn_ii\",\"sniip\",\"sniil\"}: return \"SN II\"\n",
    "    if t in {\"snib/c\",\"snibc\",\"sn-ib/c\",\"sn_ib/c\"}: return \"SN Ib/c\"\n",
    "    if t in {\"exotic\",\"other\",\"odd\"}: return \"Exotic\"\n",
    "    return str(s)\n",
    "    \n",
    "y = df[LABEL_COL].apply(_norm_label)\n",
    "df[LABEL_COL] = y\n",
    "df_str[LABEL_COL] = y\n",
    "\n",
    "# Identify numeric columns for SMOTE\n",
    "candidate_cols = [c for c in df.columns if c != LABEL_COL]\n",
    "num_cols = []\n",
    "for c in candidate_cols:\n",
    "    if pd.api.types.is_numeric_dtype(df[c]):\n",
    "        num_cols.append(c)\n",
    "        continue\n",
    "    conv = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    if conv.notna().mean() >= 0.95:\n",
    "        df[c] = conv\n",
    "        num_cols.append(c)\n",
    "\n",
    "if len(num_cols) == 0:\n",
    "    raise ValueError(\"No numeric columns detected for SMOTE. Please check the dataset.\")\n",
    "\n",
    "\n",
    "# Build SMOTE feature matrix that preserves -999 as 'unknown'\n",
    "# For each feature f:\n",
    "# f__val = numeric with -999 replaced by median (ignoring -999)\n",
    "# f__unk = 1 if f was -999, else 0\n",
    "\n",
    "X_num = df[num_cols].copy()\n",
    "\n",
    "# Track unknowns\n",
    "unknown_mask = (X_num == SENTINEL_UNKNOWN)\n",
    "\n",
    "# Compute medians ignoring sentinel and NaNs\n",
    "X_for_median = X_num.mask(unknown_mask, np.nan)\n",
    "medians = X_for_median.median(numeric_only=True)\n",
    "\n",
    "# Build SMOTE matrix\n",
    "X_smote_parts = []\n",
    "smote_feature_names = []\n",
    "for c in num_cols:\n",
    "    val_col = X_num[c].copy()\n",
    "\n",
    "    # Replace sentinel with median for SMOTE math; keep real NaNs for now\n",
    "    fill_val = medians.get(c, np.nan)\n",
    "    val_col = val_col.mask(unknown_mask[c], fill_val)\n",
    "\n",
    "    # If a column is all NaN after masking (edge case), fall back to 0.0\n",
    "    if pd.isna(fill_val):\n",
    "        val_col = val_col.fillna(0.0)\n",
    "    # Fill remaining NaNs (SMOTE cannot handle NaN)\n",
    "    else:\n",
    "        val_col = val_col.fillna(fill_val)\n",
    "\n",
    "    unk_col = unknown_mask[c].astype(float)  # 1.0 if unknown else 0.0\n",
    "\n",
    "    X_smote_parts.append(val_col.to_numpy().reshape(-1, 1))\n",
    "    smote_feature_names.append(f\"{c}__val\")\n",
    "\n",
    "    X_smote_parts.append(unk_col.to_numpy().reshape(-1, 1))\n",
    "    smote_feature_names.append(f\"{c}__unk\")\n",
    "\n",
    "X_smote = np.hstack(X_smote_parts)\n",
    "\n",
    "# Target class sizes\n",
    "counts = y.value_counts()\n",
    "n_target = counts.get(\"SN Ia\", 0)\n",
    "if n_target == 0:\n",
    "    raise ValueError(\"No 'SN Ia' examples found; cannot set target size.\")\n",
    "\n",
    "desired = {}\n",
    "for cls in [\"SN II\", \"SN Ib/c\"]:\n",
    "    n_cls = counts.get(cls, 0)\n",
    "    if n_cls == 0:\n",
    "        continue\n",
    "    desired[cls] = max(n_target, n_cls)\n",
    "\n",
    "if not desired:\n",
    "    out = df_str.copy()\n",
    "    out[\"is_synthetic\"] = \"False\"\n",
    "    out.to_csv(\"ClassImbalanced_FinalTrainingSet.csv\", index=False)\n",
    "else:\n",
    "    # k-neighbors feasibility\n",
    "    k_neighbors = 8\n",
    "    for cls, tgt in desired.items():\n",
    "        n_cls = (y == cls).sum()\n",
    "        if n_cls < (k_neighbors + 1):\n",
    "            raise ValueError(\n",
    "                f\"Class '{cls}' has only {n_cls} samples; SMOTE with k={k_neighbors} \"\n",
    "                f\"requires at least {k_neighbors+1}. Reduce k or gather more samples.\"\n",
    "            )\n",
    "\n",
    "    # Run SMOTE\n",
    "    smote = SMOTE(\n",
    "        sampling_strategy=desired,\n",
    "        k_neighbors=k_neighbors,\n",
    "        random_state=42\n",
    "    )\n",
    "    X_res, y_res = smote.fit_resample(X_smote, y.values)\n",
    "\n",
    "    # Separate originals vs synthetics\n",
    "    n_orig = len(df)\n",
    "    n_res  = len(y_res)\n",
    "    n_syn  = n_res - n_orig\n",
    "    if n_syn < 0:\n",
    "        raise RuntimeError(\"SMOTE produced fewer samples than originals; unexpected state.\")\n",
    "\n",
    "    originals = df_str.copy()\n",
    "    originals[\"is_synthetic\"] = \"False\"\n",
    "\n",
    "    # Synthetic block\n",
    "    X_syn = X_res[n_orig:, :]\n",
    "    syn = pd.DataFrame({col: \"\" for col in df_str.columns}, index=range(n_syn))\n",
    "    syn[LABEL_COL] = y_res[n_orig:]\n",
    "    syn[\"is_synthetic\"] = \"True\"\n",
    "\n",
    "    # Preserve original numeric formatting style\n",
    "    def count_decimals(s):\n",
    "        if s is None:\n",
    "            return None\n",
    "        t = str(s)\n",
    "        if t == \"\":\n",
    "            return None\n",
    "        if \"e\" in t.lower():\n",
    "            if \".\" in t:\n",
    "                return len(t.split(\"e\")[0].split(\".\")[-1])\n",
    "            return 0\n",
    "        if \".\" in t:\n",
    "            return len(t.split(\".\")[-1])\n",
    "        return 0\n",
    "\n",
    "    typical_decimals = {}\n",
    "    for c in num_cols:\n",
    "        dec_counts = []\n",
    "        for val in df_str[c].tolist():\n",
    "            if val is None or val == \"\":\n",
    "                continue\n",
    "            try:\n",
    "                _ = float(str(val).replace(\",\", \"\"))\n",
    "                d = count_decimals(val)\n",
    "                if d is not None:\n",
    "                    dec_counts.append(d)\n",
    "            except Exception:\n",
    "                pass\n",
    "        typical_decimals[c] = int(np.median(dec_counts)) if dec_counts else 0\n",
    "\n",
    "    # Reconstruct synthetic numeric features with sentinel preservation\n",
    "    for j, c in enumerate(num_cols):\n",
    "        val_idx = 2 * j\n",
    "        unk_idx = 2 * j + 1\n",
    "\n",
    "        vals = X_syn[:, val_idx]\n",
    "        unks = X_syn[:, unk_idx]\n",
    "\n",
    "        is_unknown = unks > UNK_EPS\n",
    "\n",
    "        # Build output strings\n",
    "        out_str = np.empty(n_syn, dtype=object)\n",
    "        out_str[is_unknown] = str(SENTINEL_UNKNOWN)\n",
    "\n",
    "        d = typical_decimals.get(c, 0)\n",
    "        known_vals = vals[~is_unknown]\n",
    "\n",
    "        if d <= 0:\n",
    "            # integer-like formatting for known values\n",
    "            known_fmt = pd.Series(np.round(known_vals, 0)).astype(\"Int64\").astype(str).to_numpy()\n",
    "        else:\n",
    "            fmt = \"{:.\" + str(d) + \"f}\"\n",
    "            known_fmt = np.array([fmt.format(v) if pd.notna(v) else \"\" for v in known_vals], dtype=object)\n",
    "\n",
    "        out_str[~is_unknown] = known_fmt\n",
    "        syn[c] = out_str\n",
    "\n",
    "    # Assemble + write\n",
    "    out = pd.concat([originals, syn], ignore_index=True)\n",
    "    out.to_csv(\"ClassImbalanced_FinalTrainingSet.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your-env-name",
   "language": "python",
   "name": "your-env-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
