{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a86dcf-7339-46cf-b37c-b49f889dd9ff",
   "metadata": {},
   "source": [
    "# Triplet Image Autonecoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513450e1-07a9-4643-87c5-25932bbd9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0221f-d218-46cb-bae2-05184ca1dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "MANIFEST_CSV = \"ztf_training_triplets_maxmag_manifest.csv\"\n",
    "TRIPLET_DIR  = Path(\"ztf_training_triplets_maxmag\")  # where FITS live\n",
    "\n",
    "IMAGE_SIZE   = 64      \n",
    "BATCH_SIZE   = 32\n",
    "NUM_EPOCHS   = 200\n",
    "LR           = 1e-3\n",
    "RANDOM_SEED  = 42\n",
    "DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "# Build triplet table from manifest\n",
    "def build_triplet_table(manifest_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read manifest and pivot so each row corresponds to a single triplet\n",
    "    (objectId, candid) with 3 file paths: science, difference, template.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(manifest_csv)\n",
    "\n",
    "    # Columns 'science', 'difference', 'template'\n",
    "    trip = (\n",
    "        df.pivot_table(\n",
    "            index=[\"objectId\", \"candid\", \"fid\", \"jd\"],\n",
    "            columns=\"cutout_type\",\n",
    "            values=\"file_path\",\n",
    "            aggfunc=\"first\",\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Ensure expected columns exist\n",
    "    for col in [\"science\", \"difference\", \"template\"]:\n",
    "        if col not in trip.columns:\n",
    "            trip[col] = np.nan\n",
    "\n",
    "    # Keep rows where all three exist and files actually exist\n",
    "    def has_all_files(row):\n",
    "        paths = [row[\"science\"], row[\"difference\"], row[\"template\"]]\n",
    "        return all(isinstance(p, str) and Path(p).exists() for p in paths)\n",
    "\n",
    "    trip = trip[trip.apply(has_all_files, axis=1)].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Triplets available (objectId+candid rows with all 3 cutouts): {len(trip)}\")\n",
    "    return trip\n",
    "\n",
    "\n",
    "# Data and pre-processing\n",
    "def get_first_image_data(path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Open FITS and return numpy array from the first HDU that contains data..\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "\n",
    "    with fits.open(path, memmap=False) as hdul:\n",
    "        data = None\n",
    "        for hdu in hdul:\n",
    "            if hdu.data is not None:\n",
    "                data = hdu.data\n",
    "                break\n",
    "\n",
    "    if data is None:\n",
    "        raise ValueError(f\"No data in FITS file: {path}\")\n",
    "\n",
    "    arr = np.array(data, dtype=np.float32)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def preprocess_single_cutout(arr: np.ndarray, target_size: int = IMAGE_SIZE) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Per-cutout preprocessing:\n",
    "      - Compute mean and std over finite pixels only, in float64 for stability.\n",
    "      - Subtract mean, divide by std. 'Number of std from the image mean'.\n",
    "      - Non-finite pixels set to 0 after scaling.\n",
    "      - Resize to (target_size, target_size).\n",
    "      - Return tensor of shape (1, H, W).\n",
    "    \"\"\"\n",
    "    # Ensure float32 array\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    finite_mask = np.isfinite(arr)\n",
    "\n",
    "    if finite_mask.any():\n",
    "        # Work in float64 for stable mean/std\n",
    "        finite_vals = arr[finite_mask].astype(np.float64)\n",
    "        mean = float(finite_vals.mean())\n",
    "        std = float(finite_vals.std())\n",
    "\n",
    "        # Guard against zero/NaN/inf std\n",
    "        if (not np.isfinite(std)) or (std == 0.0):\n",
    "            std = 1.0\n",
    "\n",
    "        # Do the scaling in float64\n",
    "        arr64 = arr.astype(np.float64)\n",
    "        arr64 = (arr64 - mean) / std\n",
    "        # Non-finite pixels set to 0\n",
    "        arr64[~finite_mask] = 0.0\n",
    "        arr = arr64.astype(np.float32)\n",
    "    else:\n",
    "        # If everything is non-finite, just zeros\n",
    "        arr = np.zeros_like(arr, dtype=np.float32)\n",
    "\n",
    "    # To torch tensor, add channel dim\n",
    "    tensor = torch.from_numpy(arr).unsqueeze(0)  # (1, H, W)\n",
    "\n",
    "    # Resize to target size using bilinear interpolation\n",
    "    tensor = F.interpolate(\n",
    "        tensor.unsqueeze(0),  # (1, 1, H, W)\n",
    "        size=(target_size, target_size),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).squeeze(0)  # (1, target_size, target_size)\n",
    "\n",
    "    return tensor \n",
    "\n",
    "\n",
    "def load_triplet_as_tensor(sci_path: str, diff_path: str, ref_path: str, target_size: int = IMAGE_SIZE) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load SCI, DIFF, REF cutouts from given paths, preprocess each, and stack \n",
    "    into a single tensor of shape (3, H, W).\n",
    "    \"\"\"\n",
    "    sci_arr  = get_first_image_data(sci_path)\n",
    "    diff_arr = get_first_image_data(diff_path)\n",
    "    ref_arr  = get_first_image_data(ref_path)\n",
    "\n",
    "    sci_t  = preprocess_single_cutout(sci_arr,  target_size)\n",
    "    diff_t = preprocess_single_cutout(diff_arr, target_size)\n",
    "    ref_t  = preprocess_single_cutout(ref_arr,  target_size)\n",
    "\n",
    "    x = torch.cat([sci_t, diff_t, ref_t], dim=0)  # (3, H, W) as (SCI, DIFF, REF)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Dataset\n",
    "class TripletCutoutDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset over triplets: each item is (x, x) for autoencoder training,\n",
    "    where x is a (3, H, W) tensor for one (objectId, candid).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df_triplets: pd.DataFrame, image_size: int = IMAGE_SIZE):\n",
    "        self.df = df_triplets.reset_index(drop=True).copy()\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sci_path  = row[\"science\"]\n",
    "        diff_path = row[\"difference\"]\n",
    "        ref_path  = row[\"template\"]\n",
    "\n",
    "        x = load_triplet_as_tensor(sci_path, diff_path, ref_path, self.image_size)\n",
    "\n",
    "        # Autoencoder target is the input\n",
    "        return x, x\n",
    "\n",
    "\n",
    "\n",
    "# Convolutional Autoencoder Architecture \n",
    "class ConvAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    3-layer convolutional autoencoder:\n",
    "      Encoder: 3  -> 32 -> 64 -> 128 channels, stride-2 each time.\n",
    "      Decoder: 128 -> 64 -> 32 -> 3 via ConvTranspose2d.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size: int = IMAGE_SIZE):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder: 3 conv layers, stride 2, ReLU between each\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),   # 3 x H x W -> 32 x H/2 x W/2\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 32 -> 64, H/2 -> H/4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 64 -> 128, H/4 -> H/8\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Decoder: mirror with ConvTranspose2d\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2,\n",
    "                               padding=1, output_padding=1),  # 128 -> 64, H/8 -> H/4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2,\n",
    "                               padding=1, output_padding=1),  # 64 -> 32, H/4 -> H/2\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2,\n",
    "                               padding=1, output_padding=1),  # 32 -> 3, H/2 -> H\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# Train/val/test split by objectId\n",
    "def make_splits_by_object(df_triplets: pd.DataFrame, random_seed: int = RANDOM_SEED):\n",
    "    \"\"\"\n",
    "    Split by objectId: 80% train, 10% val, 10% test.\n",
    "    Ensures the same objectId does not appear in multiple splits.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "\n",
    "    object_ids = df_triplets[\"objectId\"].astype(str).unique()\n",
    "    rng.shuffle(object_ids)\n",
    "\n",
    "    n = len(object_ids)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val   = int(0.1 * n)\n",
    "\n",
    "    train_ids = set(object_ids[:n_train])\n",
    "    val_ids   = set(object_ids[n_train:n_train + n_val])\n",
    "    test_ids  = set(object_ids[n_train + n_val:])\n",
    "\n",
    "    train_df = df_triplets[df_triplets[\"objectId\"].astype(str).isin(train_ids)].copy()\n",
    "    val_df   = df_triplets[df_triplets[\"objectId\"].astype(str).isin(val_ids)].copy()\n",
    "    test_df  = df_triplets[df_triplets[\"objectId\"].astype(str).isin(test_ids)].copy()\n",
    "\n",
    "    print(f\"Total objects with triplets: {n}\")\n",
    "    print(f\"  Train objects: {len(train_ids)} | Val objects: {len(val_ids)} | Test objects: {len(test_ids)}\")\n",
    "    print(f\"  Train triplets: {len(train_df)} | Val triplets: {len(val_df)} | Test triplets: {len(test_df)}\")\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train_autoencoder():\n",
    "    # Build full triplet table\n",
    "    df_triplets = build_triplet_table(MANIFEST_CSV)\n",
    "\n",
    "    # Split\n",
    "    train_df, val_df, test_df = make_splits_by_object(df_triplets, RANDOM_SEED)\n",
    "\n",
    "    # Datasets and loaders\n",
    "    train_ds = TripletCutoutDataset(train_df, image_size=IMAGE_SIZE)\n",
    "    val_ds   = TripletCutoutDataset(val_df,   image_size=IMAGE_SIZE)\n",
    "    test_ds  = TripletCutoutDataset(test_df,  image_size=IMAGE_SIZE)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Model, optimizer, loss\n",
    "    model = ConvAutoencoder(image_size=IMAGE_SIZE).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        n_train_samples = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", leave=False)\n",
    "        for x, y in pbar:\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            y = y.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            recon = model(x)\n",
    "            loss = criterion(recon, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = x.size(0)\n",
    "            train_loss_sum += loss.item() * batch_size\n",
    "            n_train_samples += batch_size\n",
    "\n",
    "            running = train_loss_sum / n_train_samples\n",
    "            pbar.set_postfix(train_mse=f\"{running:.5f}\")\n",
    "\n",
    "        train_loss = train_loss_sum / len(train_loader.dataset)\n",
    "\n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = x.to(DEVICE, non_blocking=True)\n",
    "                y = y.to(DEVICE, non_blocking=True)\n",
    "                recon = model(x)\n",
    "                loss = criterion(recon, y)\n",
    "                val_loss_sum += loss.item() * x.size(0)\n",
    "\n",
    "        val_loss = val_loss_sum / len(val_loader.dataset)\n",
    "\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        print(f\"[Epoch {epoch:03d}/{NUM_EPOCHS}] Train MSE: {train_loss:.6f} | Val MSE: {val_loss:.6f}\", flush=True)\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_triplet_autoencoder.pt\")\n",
    "\n",
    "    # Save training history\n",
    "    hist_df = pd.DataFrame(history)\n",
    "    hist_df.to_csv(\"triplet_autoencoder_train_history.csv\", index=False)\n",
    "    print(\"\\nTraining history saved to: triplet_autoencoder_train_history.csv\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    model.load_state_dict(torch.load(\"best_triplet_autoencoder.pt\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "    test_loss_sum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            y = y.to(DEVICE, non_blocking=True)\n",
    "            recon = model(x)\n",
    "            loss = criterion(recon, y)\n",
    "            test_loss_sum += loss.item() * x.size(0)\n",
    "\n",
    "    test_loss = test_loss_sum / len(test_loader.dataset)\n",
    "    print(f\"\\nFinal test MSE (best model): {test_loss:.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecc5bb-c5a4-4bab-a8f9-6a7f3b67eb3e",
   "metadata": {},
   "source": [
    "# Evaluate the test set in PCA space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d3d93-38bb-4610-a688-e735d3e12bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ae_pca_anomalies_test_only():\n",
    "    \"\"\"\n",
    "    Run AE and 3D PCA anomaly analysis only on the test split.\n",
    "    \"\"\"\n",
    "    # Build full triplet table and recover test split\n",
    "    df_triplets = build_triplet_table(MANIFEST_CSV)\n",
    "    train_df, val_df, test_df = make_splits_by_object(df_triplets, RANDOM_SEED)\n",
    "\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    N = len(test_df)\n",
    "\n",
    "    # Dataset & loader\n",
    "    test_ds = TripletCutoutDataset(test_df, image_size=IMAGE_SIZE)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, num_workers=0)\n",
    "\n",
    "    # Load trained AE\n",
    "    model = ConvAutoencoder(image_size=IMAGE_SIZE).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(\"best_triplet_autoencoder.pt\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    # AE forward pass on test set\n",
    "    all_X_flat = []\n",
    "    all_ae_mse = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(test_loader, desc=\"AE forward on test\", leave=False):\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            recon = model(x)\n",
    "\n",
    "            # Per-sample MSE \n",
    "            loss_per_pixel = F.mse_loss(recon, x, reduction=\"none\")\n",
    "            loss_per_sample = loss_per_pixel.view(loss_per_pixel.size(0), -1).mean(dim=1)\n",
    "            all_ae_mse.append(loss_per_sample.cpu().numpy())\n",
    "\n",
    "            # Flatten inputs for PCA\n",
    "            x_cpu = x.cpu().numpy()\n",
    "            x_flat = x_cpu.reshape(x_cpu.shape[0], -1)\n",
    "            all_X_flat.append(x_flat)\n",
    "\n",
    "    X = np.concatenate(all_X_flat, axis=0)       \n",
    "    ae_mse = np.concatenate(all_ae_mse, axis=0)  \n",
    "    assert X.shape[0] == N == ae_mse.shape[0]\n",
    "\n",
    "    print(\"Finished AE forward pass on test set.\")\n",
    "    print(f\"X shape for PCA (test only): {X.shape}\")\n",
    "    print(f\"AE MSE range (test): {ae_mse.min():.4e} – {ae_mse.max():.4e}\")\n",
    "\n",
    "    # 3D PCA on flattened test inputs\n",
    "    pca = PCA(n_components=3, random_state=RANDOM_SEED)\n",
    "    pcs_3d = pca.fit_transform(X) \n",
    "\n",
    "    # PCA reconstruction error in the original feature space\n",
    "    X_recon = pca.inverse_transform(pcs_3d)\n",
    "    pca_mse = np.mean((X - X_recon) ** 2, axis=1)\n",
    "\n",
    "\n",
    "    # Define top 1% anomalies for AE and PCA\n",
    "    ae_thresh = np.quantile(ae_mse, 0.99)\n",
    "    pca_thresh = np.quantile(pca_mse, 0.99)\n",
    "\n",
    "    is_ae_top35   = ae_mse >= ae_thresh\n",
    "    is_pca_top1  = pca_mse >= pca_thresh\n",
    "    is_both_top1 = is_ae_top35 & is_pca_top1\n",
    "\n",
    "    ae_only_top1  = is_ae_top35 & ~is_pca_top1\n",
    "    pca_only_top1 = is_pca_top1 & ~is_ae_top35\n",
    "    normal_mask   = ~(is_ae_top35 | is_pca_top1)\n",
    "\n",
    "\n",
    "    # Save test anomaly table\n",
    "    df_out = test_df.copy()\n",
    "    df_out[\"ae_mse\"] = ae_mse\n",
    "    df_out[\"pca_mse\"] = pca_mse\n",
    "    df_out[\"is_ae_top35\"] = is_ae_top35\n",
    "    df_out[\"is_pca_top1\"] = is_pca_top1\n",
    "    df_out[\"is_both_top1\"] = is_both_top1\n",
    "\n",
    "    df_out.to_csv(\"triplet_ae_pca_anomalies_test.csv\", index=False)\n",
    "    print(\"Saved test anomaly table to triplet_ae_pca_anomalies_test.csv\")\n",
    "\n",
    "    # 3D Plotly scatter for test set only\n",
    "    fig = go.Figure()\n",
    "\n",
    "    def add_trace(mask, name, color, opacity=0.9):\n",
    "        if np.any(mask):\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=pcs_3d[mask, 0],\n",
    "                    y=pcs_3d[mask, 1],\n",
    "                    z=pcs_3d[mask, 2],\n",
    "                    mode=\"markers\",\n",
    "                    name=name,\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=color,\n",
    "                        opacity=opacity,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    add_trace(normal_mask,   \"Normal (non-top-1%, test)\", \"lightblue\", opacity=0.4)\n",
    "    add_trace(ae_only_top1,  \"AE top 1% only (test)\",      \"red\",       opacity=0.9)\n",
    "    add_trace(pca_only_top1, \"PCA top 1% only (test)\",     \"orange\",    opacity=0.9)\n",
    "    add_trace(is_both_top1,  \"Top 1% in AE & PCA (test)\",  \"yellow\",    opacity=1.0)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"3D PCA of ZTF triplet cutouts (TEST SET ONLY)<br>\"\n",
    "              \"Top 1% anomalies from AE and PCA\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"PC1\",\n",
    "            yaxis_title=\"PC2\",\n",
    "            zaxis_title=\"PC3\",\n",
    "        ),\n",
    "        legend=dict(itemsizing=\"constant\"),\n",
    "        margin=dict(l=0, r=0, b=0, t=40),\n",
    "    )\n",
    "\n",
    "    html_path = \"triplet_ae_pca_3d_anomalies_test.html\"\n",
    "    fig.write_html(html_path, auto_open=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_ae_pca_anomalies_test_only()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08899d3-c811-452c-89c1-45e82cf175d3",
   "metadata": {},
   "source": [
    "## Top 10 Anomalies from the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9461d5-f15f-44c5-ab9d-37ec9dbbdf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_top_ae_anomalies_training_rows_test(\n",
    "    training_csv_path: str = \"training_data.csv\",\n",
    "    output_csv_path: str = \"tripletimage_AE_top10anomalies.csv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Compute AE reconstruction loss on the test split only.\n",
    "    2) Select top 3.5% AE anomalies within the test set.\n",
    "    3) Compute object-level AE loss for those anomalies (aggregated over selected triplets).\n",
    "    4) Match their objectId values to `training_data.csv`.\n",
    "    5) Save all rows from training_data.csv whose objectId is in that\n",
    "       top-3.5% AE anomaly set (test-only) to `output_csv_path`,\n",
    "       Including the reconstruction loss values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build full triplet table and recover test split\n",
    "    df_triplets = build_triplet_table(MANIFEST_CSV)\n",
    "    train_df, val_df, test_df = make_splits_by_object(df_triplets, RANDOM_SEED)\n",
    "\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    N = len(test_df)\n",
    "    print(f\"Number of test triplets: {N}\")\n",
    "\n",
    "    # Dataset and loader \n",
    "    test_ds = TripletCutoutDataset(test_df, image_size=IMAGE_SIZE)\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    # Load trained AE\n",
    "    model = ConvAutoencoder(image_size=IMAGE_SIZE).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(\"best_triplet_autoencoder.pt\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    # AE forward pass on TEST set to get per-sample MSE\n",
    "    all_ae_mse = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in tqdm(test_loader, desc=\"AE forward on TEST (for losses)\", leave=False):\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            recon = model(x)\n",
    "\n",
    "            # Per-sample MSE = mean over channels and pixels\n",
    "            loss_per_pixel = F.mse_loss(recon, x, reduction=\"none\")\n",
    "            loss_per_sample = loss_per_pixel.view(loss_per_pixel.size(0), -1).mean(dim=1)\n",
    "            all_ae_mse.append(loss_per_sample.cpu().numpy())\n",
    "\n",
    "    ae_mse = np.concatenate(all_ae_mse, axis=0)  # shape (N,)\n",
    "    assert ae_mse.shape[0] == N\n",
    "    print(f\"AE MSE range (TEST): {ae_mse.min():.4e} – {ae_mse.max():.4e}\")\n",
    "\n",
    "    # Identify top 3.5% AE anomalies in the TEST set\n",
    "    ae_thresh = np.quantile(ae_mse, 0.965)\n",
    "    is_ae_top35 = ae_mse >= ae_thresh\n",
    "    idx_top = np.where(is_ae_top35)[0]\n",
    "\n",
    "    print(f\"Top 3.5% AE anomalies (TEST): {len(idx_top)} / {N}\")\n",
    "    if len(idx_top) == 0:\n",
    "        print(\"No top 3.5% anomalies found in TEST (unexpected). Exiting.\")\n",
    "        return\n",
    "\n",
    "    test_with_loss = test_df.copy()\n",
    "    test_with_loss[\"ae_mse\"] = ae_mse\n",
    "    test_top = test_with_loss.loc[is_ae_top35].copy()\n",
    "\n",
    "    # Object-level aggregation\n",
    "    obj_loss_summary = (\n",
    "        test_top.groupby(test_top[\"objectId\"].astype(str))[\"ae_mse\"]\n",
    "        .agg(\n",
    "            ae_mse_mean_top35_test=\"mean\",\n",
    "            ae_mse_max_top35_test=\"max\",\n",
    "            ae_mse_median_top35_test=\"median\",\n",
    "            n_triplets_top35_test=\"count\",\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={\"objectId\": \"objectId_str\"})\n",
    "    )\n",
    "\n",
    "    top_obj_ids = obj_loss_summary[\"objectId_str\"].unique()\n",
    "\n",
    "\n",
    "    # Load training_data.csv and match on objectId\n",
    "    train_df_full = pd.read_csv(training_csv_path)\n",
    "    print(f\"Loaded training data from {training_csv_path} with {len(train_df_full)} rows\")\n",
    "\n",
    "    # Compare objectId as string on both sides\n",
    "    train_df_full[\"objectId_str\"] = train_df_full[\"objectId\"].astype(str)\n",
    "\n",
    "    matched_df = train_df_full[train_df_full[\"objectId_str\"].isin(top_obj_ids)].copy()\n",
    "    print(f\"Rows in training_data.csv matching TEST AE top-3.5% objectIds: {len(matched_df)}\")\n",
    "\n",
    "    missing_ids = set(top_obj_ids) - set(train_df_full[\"objectId_str\"].unique())\n",
    "    if missing_ids:\n",
    "        print(f\"Warning: {len(missing_ids)} AE-top-3.5% TEST objectIds not found in training_data.csv\")\n",
    "\n",
    "    matched_df = matched_df.merge(\n",
    "        obj_loss_summary,\n",
    "        on=\"objectId_str\",\n",
    "        how=\"left\",\n",
    "        validate=\"many_to_one\",\n",
    "    )\n",
    "\n",
    "    matched_df.drop(columns=[\"objectId_str\"], inplace=True)\n",
    "\n",
    "    matched_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Saved test AE top 10 anomaly rows (with AE losses) to: {output_csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    export_top_ae_anomalies_training_rows_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your-env-name",
   "language": "python",
   "name": "your-env-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
